{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling training data\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT year, plurality, apgar_5min, \n",
    "       mother_age, father_age,    \n",
    "       gestation_weeks, ever_born\n",
    "       ,case when mother_married = true \n",
    "             then 1 else 0 end as mother_married\n",
    "       ,weight_pounds as weight\n",
    "  FROM  `bigquery-public-data.samples.natality`\n",
    "  order by rand() \n",
    "  limit 10000\n",
    "\"\"\"\n",
    "\n",
    "natalityDF = client.query(sql).to_dataframe().fillna(0)\n",
    "natalityDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a model and saving to cloud\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "\n",
    "# fit and pickle a model \n",
    "model = LinearRegression()\n",
    "model.fit(natalityDF.iloc[:,1:8], natalityDF['weight'])\n",
    "pickle.dump(model, open(\"natality.pkl\", 'wb'))\n",
    "\n",
    "# Save to GCS\n",
    "bucket = storage.Client().get_bucket('dsp_model_store')\n",
    "blob = bucket.blob('natality/sklearn-linear')\n",
    "blob.upload_from_filename('natality.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real data (without limit)\n",
    "import apache_beam as beam\n",
    "import argparse\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "from apache_beam.io.gcp.bigquery import parse_table_schema_from_json\n",
    "import json\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT year, plurality, apgar_5min, \n",
    "    mother_age, father_age,    \n",
    "       gestation_weeks, ever_born\n",
    "       ,case when mother_married = true \n",
    "          then 1 else 0 end as mother_married\n",
    "      ,weight_pounds as weight\n",
    "      ,current_timestamp as time\n",
    "      ,GENERATE_UUID() as guid\n",
    "    FROM `bigquery-public-data.samples.natality` \n",
    "    rand() \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyDoFn(beam.DoFn):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._model = None\n",
    "        from google.cloud import storage\n",
    "        import pandas as pd\n",
    "        import pickle as pkl\n",
    "        self._storage = storage\n",
    "        self._pkl = pkl\n",
    "        self._pd = pd\n",
    "     \n",
    "    def process(self, element):\n",
    "        if self._model is None:\n",
    "            bucket = self._storage.Client().get_bucket('model_store')\n",
    "            blob = bucket.get_blob('natality/sklearn-linear')\n",
    "            self._model =self._pkl.loads(blob.download_as_string())\n",
    "        \n",
    "        new_x = self._pd.DataFrame.from_dict(element, \n",
    "                            orient = \"index\").transpose().fillna(0)   \n",
    "        weight = self._model.predict(new_x.iloc[:,1:8])[0]\n",
    "        return [ { 'guid': element['guid'], 'weight': weight, \n",
    "                                   'time': str(element['time']) } ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a72fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = parse_table_schema_from_json(json.dumps({'fields':\n",
    "            [ { 'name': 'guid', 'type': 'STRING'},\n",
    "              { 'name': 'weight', 'type': 'FLOAT64'},\n",
    "              { 'name': 'time', 'type': 'STRING'} ]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c013f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pipeline options \n",
    "parser = argparse.ArgumentParser()\n",
    "known_args, pipeline_args = parser.parse_known_args(None)\n",
    "pipeline_options = PipelineOptions(pipeline_args)\n",
    "\n",
    "# define the pipeline steps\n",
    "p = beam.Pipeline(options=pipeline_options)\n",
    "data = p | 'Read from BigQuery' >> beam.io.Read(\n",
    "       beam.io.BigQuerySource(query=query, use_standard_sql=True))\n",
    "scored = data | 'Apply Model' >> beam.ParDo(ApplyDoFn())\n",
    "scored | 'Save to BigQuery' >> beam.io.Write(beam.io.BigQuerySink(\n",
    "                'weight_preds', 'dataflow_beam_pipeline', schema = schema,\n",
    "   create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "   write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND))\n",
    "\n",
    "# run the pipeline\n",
    "result = p.run()\n",
    "result.wait_until_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publish to datastore\n",
    "class PublishDoFn(beam.DoFn):\n",
    "    \n",
    "    def __init__(self):\n",
    "        from google.cloud import datastore       \n",
    "        self._ds = datastore\n",
    "    \n",
    "    def process(self, element):\n",
    "        client = self._ds.Client()\n",
    "        key = client.key('natality-guid', element['guid'])\n",
    "        entity = self._ds.Entity(key)\n",
    "        entity['weight'] = element['weight']         \n",
    "        entity['time'] = element['time']\n",
    "        client.put(entity)\n",
    "\n",
    "scored | 'Create entities' >> beam.ParDo(PublishDoFn())\n",
    "\n",
    "# Testing (datastore publish)\n",
    "from google.cloud import datastore\n",
    "client = datastore.Client()\n",
    "query = client.query(kind='natality-guid')\n",
    "\n",
    "query_iter = query.fetch()\n",
    "for entity in query_iter:\n",
    "    print(entity)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
