{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BigQuery to GCS\n",
    "\"\"\"\n",
    "create table dsp_demo.natality as (\n",
    "  select *\n",
    "  from `bigquery-public-data.samples.natality`\n",
    "  order by rand()\n",
    "  limit 10000 \n",
    ") \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d620a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp dsdemo.json s3://spark_pipeline/secrets/gcp_credentials.json\n",
    "\n",
    "!aws s3 ls  s3://spark_pipeline/secrets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75690945",
   "metadata": {},
   "outputs": [],
   "source": [
    "creds_file = '/databricks/gcp_credentials.json'\n",
    "creds = sc.textFile('s3://spark_pipeline/secrets/gcp_credentials.json')\n",
    "\n",
    "with open(creds_file, 'w') as file:\n",
    "    for line in creds.take(100):\n",
    "        file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \n",
    "           \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.gs.project.id\", \n",
    "                                                 \"my_project_id\")\n",
    "sc._jsc.hadoopConfiguration().set(\n",
    "         \"mapred.bq.auth.service.account.json.keyfile\", creds_file)\n",
    "sc._jsc.hadoopConfiguration().set(\n",
    "             \"fs.gs.auth.service.account.json.keyfile\", creds_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caec0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "natality_path = \"gs://dsp_model_store/natality/avro\"\n",
    "natality_df = spark.read.format(\"avro\").load(natality_path)\n",
    "display(natality_df)\n",
    "\n",
    "natality_df.createOrReplaceTempView(\"natality_df\")\n",
    "\n",
    "natality_df = spark.sql(\"\"\"\n",
    "SELECT year, plurality, apgar_5min, \n",
    "       mother_age, father_age,    \n",
    "       gestation_weeks, ever_born\n",
    "       ,case when mother_married = true \n",
    "             then 1 else 0 end as mother_married\n",
    "       ,weight_pounds as weight\n",
    "       ,case when rand() < 0.5 then 1 else 0 end as test\n",
    "from natality_df       \n",
    "\"\"\").fillna(0)\n",
    "\n",
    "trainDF = natality_df.filter(\"test == 0\")\n",
    "testDF = natality_df.filter(\"test == 1\")\n",
    "display(natality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# create a vector representation\n",
    "assembler = VectorAssembler(inputCols= trainDF.schema.names[0:8],\n",
    "                            outputCol=\"features\" )\n",
    "\n",
    "trainVec = assembler.transform(trainDF).select('weight','features')\n",
    "testVec = assembler.transform(testDF).select('weight', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccea813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "from pyspark.ml.tuning import ParamGridBuilder \n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "folds = 3\n",
    "rf_trees = [ 50, 100  ]\n",
    "rf_depth = [ 4, 5 ]\n",
    "\n",
    "rf= RandomForestRegressor(featuresCol='features',labelCol='weight')\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, rf_trees).addGrid(rf.maxDepth, rf_depth).build()\n",
    "crossval = CrossValidator(estimator=rf, estimatorParamMaps =\n",
    "                         paramGrid, evaluator=RegressionEvaluator(\n",
    "                              labelCol='weight'), numFolds = folds)       \n",
    "rfModel = crossval.fit(trainVec)\n",
    "   \n",
    "predsDF = rfModel.transform(testVec).select(\"weight\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "out_path = \"gs://spark_pipeline/natality/preds-{time}/\".\n",
    "                             format(time = int(time.time()*1000))\n",
    "predsDF.write.mode('overwrite').format(\"avro\").save(out_path)\n",
    "print(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
